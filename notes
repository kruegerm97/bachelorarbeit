TODO notes: Section 4 ChatGPT als Quelle angeben

Korrektheit des Codes und der Ergebnisse (Spaltenanzahl und Reihenfolge richtig?), Performance des Codes im Bezug
auf Laufzeit und Ressourcennutzung, Qualität des Codes (Struktur des
Codes, Kommentare/Dokumentation, verwendete Libraries), Wartbarkeit und
ist der Code erweiterbar.
Pro Test case mehrere Generierungen und dann tests dafuer schreiben und bewerten, wie viele loesungen alle tests erfuellen.
Bspw 10 Generierungen -> Pass@10 wie viel % sind erfolgreich, bei erfolgreichen Ausfuehrungen Code manuell bewerten
welcher pandas dataframe wird benutzt. fuer visualisierung einen vorgeben und schauen ob er richtig benutzt wird.
Selbst Plot generieren und mit generierten Plot vergleichen
Aggregationen, Joins einnehmen, Filterung, Zeitreihe, Sortierung
Bei visualisierung pandas dataframe vorgeben

Zur Methodik: Pro Testcase eine offene unspezifische Prompt und eine Prompt mit genauen Vorgaben (Z.B. welchen Pandas Dataframe fuer Visualisierung; Join basierend auf LOR Schluessel, etc.).

Probleme bei der Durchführung:
ChatGPT nimmt keine Dateien wie excel etc an. Man muss API benutzen und die Tabelle als CSV Content übergeben.

Gesamte responses in Arbeit packen

Fragen:
Wann genau soll Code angezeigt werden?
Wann Anmeldung Kolloqium?
Ursprungsdatei Daten auch in die Arbeit?
Wie ChatGPT als Quelle angeben? Selbst text beschrieben und von ChatGPT ausschreiben und Latex generieren lassen.

Daten von Open Data besser beschreiben und was dabei rauskommen soll. Neues Kapitel vor Methodik. Da Testfaelle beschreiben
-> fuer empirische Analyse werden Daten runtergebrochen zu pd mit nur oberbezirken 
Grundlagenkapitel Prompting
mehrere Prompting strategien (bspw. mehr Metadaten (welche Spalte ist relevant etc.)) (chain of thought) 3 verschiedene Prompts pro testfall und pro prompt 5 Ausfuehrungen
Ergebnisse mit barcharts oder tabellen (Tabelle Kopfzeile mit Prompts, erste Spalte kommen Ausfuehrungen)
nicht volle Sheets als csv geben, sondern nur erste Zeilen (oder gar nicht csv sondern als Pandas Dataframe)
eine prompt nur aus augen des normalen users, eine mit metadaten und eine mit chain of thought.
(Ein Testfall mit neuer Excel mit nur einem Sheet fuer verschiedenen Aufwand) entfaellt weil Benutzung von Pandas Dataframe
Nur die Oberbezirke benutzen, alle Unterbezirke aus der Excel loeschen.
ein testfall alle sheets joinen aber nicht sortieren.

Keine Visualisierung (Testfall 4 raus.)
Testfall 5 prozentuale Veraenderung der Straftaten insgesamt pro Bezirk (auch in Tabelle)
fuer jedes Jahr ein Pandas Dataframe nur fuer Oberbezirke und diese in Prompt

Prio:
neues Kapitel vor Methodik zu Ausgangsdaten und worauf sie runtergebrochen werden und was bei den Testfaellen rauskommen soll.
Auch dataframe aus eigener Programmierung, der verwendet werden soll von den Skripten.
Wenn Zeit auch fertige Tabelle aus eigener Programmierung fuer die Testfaelle um gewollte Ergebnisse der Testfaelle zu haben.
Auch erklaeren, dass verschiedene Prompting Strategien pro Testfall verwendet werden.