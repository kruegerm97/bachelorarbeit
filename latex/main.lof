\babel@toc {ngerman}{}\relax 
\babel@toc {ngerman}{}\relax 
\contentsline {figure}{\numberline {1}{\ignorespaces Leistungsvergleich verschiedener Modellgrößen (nach Jiang et al. (2024), basierend auf 'A Survey on Large Language Models for Code Generation'\blx@tocontentsinit {0}\cite {jiang2024surveylargelanguagemodels}).}}{11}{figure.1}%
\contentsline {figure}{\numberline {2}{\ignorespaces Chronologische Übersicht von Large Language Models für die Code Generierung der letzten Jahre (nach Jiang et al. (2024), basierend auf 'A Survey on Large Language Models for Code Generation')\blx@tocontentsinit {0}\cite {jiang2024surveylargelanguagemodels}.}}{14}{figure.2}%
\contentsline {figure}{\numberline {3}{\ignorespaces Übersicht der Verteilung von veröffentlichten Arbeiten zu LLMs und Software Engineering der letzten Jahren (nach Jiang et al. (2024), basierend auf 'A Survey on Large Language Models for Code Generation'\blx@tocontentsinit {0}\cite {jiang2024surveylargelanguagemodels}).}}{16}{figure.3}%
\contentsline {figure}{\numberline {4}{\ignorespaces Vergleich der Ergebnisse von \emph {HumanEval} und \emph {EvalPlus} (nach Liu et al. (2023), basierend auf ``Is your Code Generated by ChatGPT Really Correct? Rigorous Evaluation of Large Language Models for Code Generation''\blx@tocontentsinit {0}\cite {NEURIPS2023_43e9d647}).}}{17}{figure.4}%
